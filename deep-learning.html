<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>10 Deep Learning | An Introduction to Statistical Learning</title>
  <meta name="description" content="10 Deep Learning | An Introduction to Statistical Learning" />
  <meta name="generator" content="bookdown 0.29.3 and GitBook 2.6.7" />

  <meta property="og:title" content="10 Deep Learning | An Introduction to Statistical Learning" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="10 Deep Learning | An Introduction to Statistical Learning" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="support-vector-machines.html"/>
<link rel="next" href="survival-analysis-and-censored-data.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="islrv2.css" type="text/css" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/aaaakshat/cm-web-fonts@latest/fonts.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ISLRv2 Solutions</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="statistical-learning.html"><a href="statistical-learning.html"><i class="fa fa-check"></i><b>2</b> Statistical Learning</a><ul>
<li class="chapter" data-level="2.1" data-path="statistical-learning.html"><a href="statistical-learning.html#conceptual"><i class="fa fa-check"></i><b>2.1</b> Conceptual</a><ul>
<li class="chapter" data-level="2.1.1" data-path="statistical-learning.html"><a href="statistical-learning.html#question-1"><i class="fa fa-check"></i><b>2.1.1</b> Question 1</a></li>
<li class="chapter" data-level="2.1.2" data-path="statistical-learning.html"><a href="statistical-learning.html#question-2"><i class="fa fa-check"></i><b>2.1.2</b> Question 2</a></li>
<li class="chapter" data-level="2.1.3" data-path="statistical-learning.html"><a href="statistical-learning.html#question-3"><i class="fa fa-check"></i><b>2.1.3</b> Question 3</a></li>
<li class="chapter" data-level="2.1.4" data-path="statistical-learning.html"><a href="statistical-learning.html#question-4"><i class="fa fa-check"></i><b>2.1.4</b> Question 4</a></li>
<li class="chapter" data-level="2.1.5" data-path="statistical-learning.html"><a href="statistical-learning.html#question-5"><i class="fa fa-check"></i><b>2.1.5</b> Question 5</a></li>
<li class="chapter" data-level="2.1.6" data-path="statistical-learning.html"><a href="statistical-learning.html#question-6"><i class="fa fa-check"></i><b>2.1.6</b> Question 6</a></li>
<li class="chapter" data-level="2.1.7" data-path="statistical-learning.html"><a href="statistical-learning.html#question-7"><i class="fa fa-check"></i><b>2.1.7</b> Question 7</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="statistical-learning.html"><a href="statistical-learning.html#applied"><i class="fa fa-check"></i><b>2.2</b> Applied</a><ul>
<li class="chapter" data-level="2.2.1" data-path="statistical-learning.html"><a href="statistical-learning.html#question-8"><i class="fa fa-check"></i><b>2.2.1</b> Question 8</a></li>
<li class="chapter" data-level="2.2.2" data-path="statistical-learning.html"><a href="statistical-learning.html#question-9"><i class="fa fa-check"></i><b>2.2.2</b> Question 9</a></li>
<li class="chapter" data-level="2.2.3" data-path="statistical-learning.html"><a href="statistical-learning.html#question-10"><i class="fa fa-check"></i><b>2.2.3</b> Question 10</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>3</b> Linear Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="linear-regression.html"><a href="linear-regression.html#conceptual-1"><i class="fa fa-check"></i><b>3.1</b> Conceptual</a><ul>
<li class="chapter" data-level="3.1.1" data-path="linear-regression.html"><a href="linear-regression.html#question-1-1"><i class="fa fa-check"></i><b>3.1.1</b> Question 1</a></li>
<li class="chapter" data-level="3.1.2" data-path="linear-regression.html"><a href="linear-regression.html#question-2-1"><i class="fa fa-check"></i><b>3.1.2</b> Question 2</a></li>
<li class="chapter" data-level="3.1.3" data-path="linear-regression.html"><a href="linear-regression.html#question-3-1"><i class="fa fa-check"></i><b>3.1.3</b> Question 3</a></li>
<li class="chapter" data-level="3.1.4" data-path="linear-regression.html"><a href="linear-regression.html#question-4-1"><i class="fa fa-check"></i><b>3.1.4</b> Question 4</a></li>
<li class="chapter" data-level="3.1.5" data-path="linear-regression.html"><a href="linear-regression.html#question-5-1"><i class="fa fa-check"></i><b>3.1.5</b> Question 5</a></li>
<li class="chapter" data-level="3.1.6" data-path="linear-regression.html"><a href="linear-regression.html#question-6-1"><i class="fa fa-check"></i><b>3.1.6</b> Question 6</a></li>
<li class="chapter" data-level="3.1.7" data-path="linear-regression.html"><a href="linear-regression.html#question-7-1"><i class="fa fa-check"></i><b>3.1.7</b> Question 7</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linear-regression.html"><a href="linear-regression.html#applied-1"><i class="fa fa-check"></i><b>3.2</b> Applied</a><ul>
<li class="chapter" data-level="3.2.1" data-path="linear-regression.html"><a href="linear-regression.html#question-8-1"><i class="fa fa-check"></i><b>3.2.1</b> Question 8</a></li>
<li class="chapter" data-level="3.2.2" data-path="linear-regression.html"><a href="linear-regression.html#question-9-1"><i class="fa fa-check"></i><b>3.2.2</b> Question 9</a></li>
<li class="chapter" data-level="3.2.3" data-path="linear-regression.html"><a href="linear-regression.html#question-10-1"><i class="fa fa-check"></i><b>3.2.3</b> Question 10</a></li>
<li class="chapter" data-level="3.2.4" data-path="linear-regression.html"><a href="linear-regression.html#question-11"><i class="fa fa-check"></i><b>3.2.4</b> Question 11</a></li>
<li class="chapter" data-level="3.2.5" data-path="linear-regression.html"><a href="linear-regression.html#question-12"><i class="fa fa-check"></i><b>3.2.5</b> Question 12</a></li>
<li class="chapter" data-level="3.2.6" data-path="linear-regression.html"><a href="linear-regression.html#question-13"><i class="fa fa-check"></i><b>3.2.6</b> Question 13</a></li>
<li class="chapter" data-level="3.2.7" data-path="linear-regression.html"><a href="linear-regression.html#question-14"><i class="fa fa-check"></i><b>3.2.7</b> Question 14</a></li>
<li class="chapter" data-level="3.2.8" data-path="linear-regression.html"><a href="linear-regression.html#question-15"><i class="fa fa-check"></i><b>3.2.8</b> Question 15</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>4</b> Classification</a><ul>
<li class="chapter" data-level="4.1" data-path="classification.html"><a href="classification.html#conceptual-2"><i class="fa fa-check"></i><b>4.1</b> Conceptual</a><ul>
<li class="chapter" data-level="4.1.1" data-path="classification.html"><a href="classification.html#question-1-2"><i class="fa fa-check"></i><b>4.1.1</b> Question 1</a></li>
<li class="chapter" data-level="4.1.2" data-path="classification.html"><a href="classification.html#question-2-2"><i class="fa fa-check"></i><b>4.1.2</b> Question 2</a></li>
<li class="chapter" data-level="4.1.3" data-path="classification.html"><a href="classification.html#question-3-2"><i class="fa fa-check"></i><b>4.1.3</b> Question 3</a></li>
<li class="chapter" data-level="4.1.4" data-path="classification.html"><a href="classification.html#question-4-2"><i class="fa fa-check"></i><b>4.1.4</b> Question 4</a></li>
<li class="chapter" data-level="4.1.5" data-path="classification.html"><a href="classification.html#question-5-2"><i class="fa fa-check"></i><b>4.1.5</b> Question 5</a></li>
<li class="chapter" data-level="4.1.6" data-path="classification.html"><a href="classification.html#question-6-2"><i class="fa fa-check"></i><b>4.1.6</b> Question 6</a></li>
<li class="chapter" data-level="4.1.7" data-path="classification.html"><a href="classification.html#question-7-2"><i class="fa fa-check"></i><b>4.1.7</b> Question 7</a></li>
<li class="chapter" data-level="4.1.8" data-path="classification.html"><a href="classification.html#question-8-2"><i class="fa fa-check"></i><b>4.1.8</b> Question 8</a></li>
<li class="chapter" data-level="4.1.9" data-path="classification.html"><a href="classification.html#question-9-2"><i class="fa fa-check"></i><b>4.1.9</b> Question 9</a></li>
<li class="chapter" data-level="4.1.10" data-path="classification.html"><a href="classification.html#question-10-2"><i class="fa fa-check"></i><b>4.1.10</b> Question 10</a></li>
<li class="chapter" data-level="4.1.11" data-path="classification.html"><a href="classification.html#question-11-1"><i class="fa fa-check"></i><b>4.1.11</b> Question 11</a></li>
<li class="chapter" data-level="4.1.12" data-path="classification.html"><a href="classification.html#question-12-1"><i class="fa fa-check"></i><b>4.1.12</b> Question 12</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="classification.html"><a href="classification.html#applied-2"><i class="fa fa-check"></i><b>4.2</b> Applied</a><ul>
<li class="chapter" data-level="4.2.1" data-path="classification.html"><a href="classification.html#question-13-1"><i class="fa fa-check"></i><b>4.2.1</b> Question 13</a></li>
<li class="chapter" data-level="4.2.2" data-path="classification.html"><a href="classification.html#question-14-1"><i class="fa fa-check"></i><b>4.2.2</b> Question 14</a></li>
<li class="chapter" data-level="4.2.3" data-path="classification.html"><a href="classification.html#question-15-1"><i class="fa fa-check"></i><b>4.2.3</b> Question 15</a></li>
<li class="chapter" data-level="4.2.4" data-path="classification.html"><a href="classification.html#question-13-2"><i class="fa fa-check"></i><b>4.2.4</b> Question 13</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="resampling-methods.html"><a href="resampling-methods.html"><i class="fa fa-check"></i><b>5</b> Resampling Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="resampling-methods.html"><a href="resampling-methods.html#conceptual-3"><i class="fa fa-check"></i><b>5.1</b> Conceptual</a><ul>
<li class="chapter" data-level="5.1.1" data-path="resampling-methods.html"><a href="resampling-methods.html#question-1-3"><i class="fa fa-check"></i><b>5.1.1</b> Question 1</a></li>
<li class="chapter" data-level="5.1.2" data-path="resampling-methods.html"><a href="resampling-methods.html#question-2-3"><i class="fa fa-check"></i><b>5.1.2</b> Question 2</a></li>
<li class="chapter" data-level="5.1.3" data-path="resampling-methods.html"><a href="resampling-methods.html#question-3-3"><i class="fa fa-check"></i><b>5.1.3</b> Question 3</a></li>
<li class="chapter" data-level="5.1.4" data-path="resampling-methods.html"><a href="resampling-methods.html#question-4-3"><i class="fa fa-check"></i><b>5.1.4</b> Question 4</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="resampling-methods.html"><a href="resampling-methods.html#applied-3"><i class="fa fa-check"></i><b>5.2</b> Applied</a><ul>
<li class="chapter" data-level="5.2.1" data-path="resampling-methods.html"><a href="resampling-methods.html#question-5-3"><i class="fa fa-check"></i><b>5.2.1</b> Question 5</a></li>
<li class="chapter" data-level="5.2.2" data-path="resampling-methods.html"><a href="resampling-methods.html#question-6-3"><i class="fa fa-check"></i><b>5.2.2</b> Question 6</a></li>
<li class="chapter" data-level="5.2.3" data-path="resampling-methods.html"><a href="resampling-methods.html#question-7-3"><i class="fa fa-check"></i><b>5.2.3</b> Question 7</a></li>
<li class="chapter" data-level="5.2.4" data-path="resampling-methods.html"><a href="resampling-methods.html#question-8-3"><i class="fa fa-check"></i><b>5.2.4</b> Question 8</a></li>
<li class="chapter" data-level="5.2.5" data-path="resampling-methods.html"><a href="resampling-methods.html#question-9-3"><i class="fa fa-check"></i><b>5.2.5</b> Question 9</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html"><i class="fa fa-check"></i><b>6</b> Linear Model Selection and Regularization</a><ul>
<li class="chapter" data-level="6.1" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#conceptual-4"><i class="fa fa-check"></i><b>6.1</b> Conceptual</a><ul>
<li class="chapter" data-level="6.1.1" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-1-4"><i class="fa fa-check"></i><b>6.1.1</b> Question 1</a></li>
<li class="chapter" data-level="6.1.2" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-2-4"><i class="fa fa-check"></i><b>6.1.2</b> Question 2</a></li>
<li class="chapter" data-level="6.1.3" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-3-4"><i class="fa fa-check"></i><b>6.1.3</b> Question 3</a></li>
<li class="chapter" data-level="6.1.4" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-4-4"><i class="fa fa-check"></i><b>6.1.4</b> Question 4</a></li>
<li class="chapter" data-level="6.1.5" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-5-4"><i class="fa fa-check"></i><b>6.1.5</b> Question 5</a></li>
<li class="chapter" data-level="6.1.6" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-6-4"><i class="fa fa-check"></i><b>6.1.6</b> Question 6</a></li>
<li class="chapter" data-level="6.1.7" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-7-4"><i class="fa fa-check"></i><b>6.1.7</b> Question 7</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#applied-4"><i class="fa fa-check"></i><b>6.2</b> Applied</a><ul>
<li class="chapter" data-level="6.2.1" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-8-4"><i class="fa fa-check"></i><b>6.2.1</b> Question 8</a></li>
<li class="chapter" data-level="6.2.2" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-9-4"><i class="fa fa-check"></i><b>6.2.2</b> Question 9</a></li>
<li class="chapter" data-level="6.2.3" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-10-3"><i class="fa fa-check"></i><b>6.2.3</b> Question 10</a></li>
<li class="chapter" data-level="6.2.4" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-11-2"><i class="fa fa-check"></i><b>6.2.4</b> Question 11</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html"><i class="fa fa-check"></i><b>7</b> Moving Beyond Linearity</a><ul>
<li class="chapter" data-level="7.1" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#conceptual-5"><i class="fa fa-check"></i><b>7.1</b> Conceptual</a><ul>
<li class="chapter" data-level="7.1.1" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-1-5"><i class="fa fa-check"></i><b>7.1.1</b> Question 1</a></li>
<li class="chapter" data-level="7.1.2" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-2-5"><i class="fa fa-check"></i><b>7.1.2</b> Question 2</a></li>
<li class="chapter" data-level="7.1.3" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-3-5"><i class="fa fa-check"></i><b>7.1.3</b> Question 3</a></li>
<li class="chapter" data-level="7.1.4" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-4-5"><i class="fa fa-check"></i><b>7.1.4</b> Question 4</a></li>
<li class="chapter" data-level="7.1.5" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-5-5"><i class="fa fa-check"></i><b>7.1.5</b> Question 5</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#applied-5"><i class="fa fa-check"></i><b>7.2</b> Applied</a><ul>
<li class="chapter" data-level="7.2.1" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-6-5"><i class="fa fa-check"></i><b>7.2.1</b> Question 6</a></li>
<li class="chapter" data-level="7.2.2" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-7-5"><i class="fa fa-check"></i><b>7.2.2</b> Question 7</a></li>
<li class="chapter" data-level="7.2.3" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-8-5"><i class="fa fa-check"></i><b>7.2.3</b> Question 8</a></li>
<li class="chapter" data-level="7.2.4" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-9-5"><i class="fa fa-check"></i><b>7.2.4</b> Question 9</a></li>
<li class="chapter" data-level="7.2.5" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-10-4"><i class="fa fa-check"></i><b>7.2.5</b> Question 10</a></li>
<li class="chapter" data-level="7.2.6" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-11-3"><i class="fa fa-check"></i><b>7.2.6</b> Question 11</a></li>
<li class="chapter" data-level="7.2.7" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-12-2"><i class="fa fa-check"></i><b>7.2.7</b> Question 12</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="tree-based-methods.html"><a href="tree-based-methods.html"><i class="fa fa-check"></i><b>8</b> Tree-Based Methods</a><ul>
<li class="chapter" data-level="8.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#conceptual-6"><i class="fa fa-check"></i><b>8.1</b> Conceptual</a><ul>
<li class="chapter" data-level="8.1.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-1-6"><i class="fa fa-check"></i><b>8.1.1</b> Question 1</a></li>
<li class="chapter" data-level="8.1.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-2-6"><i class="fa fa-check"></i><b>8.1.2</b> Question 2</a></li>
<li class="chapter" data-level="8.1.3" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-3-6"><i class="fa fa-check"></i><b>8.1.3</b> Question 3</a></li>
<li class="chapter" data-level="8.1.4" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-4-6"><i class="fa fa-check"></i><b>8.1.4</b> Question 4</a></li>
<li class="chapter" data-level="8.1.5" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-5-6"><i class="fa fa-check"></i><b>8.1.5</b> Question 5</a></li>
<li class="chapter" data-level="8.1.6" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-6-6"><i class="fa fa-check"></i><b>8.1.6</b> Question 6</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#applied-6"><i class="fa fa-check"></i><b>8.2</b> Applied</a><ul>
<li class="chapter" data-level="8.2.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-7-6"><i class="fa fa-check"></i><b>8.2.1</b> Question 7</a></li>
<li class="chapter" data-level="8.2.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-8-6"><i class="fa fa-check"></i><b>8.2.2</b> Question 8</a></li>
<li class="chapter" data-level="8.2.3" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-9-6"><i class="fa fa-check"></i><b>8.2.3</b> Question 9</a></li>
<li class="chapter" data-level="8.2.4" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-10-5"><i class="fa fa-check"></i><b>8.2.4</b> Question 10</a></li>
<li class="chapter" data-level="8.2.5" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-11-4"><i class="fa fa-check"></i><b>8.2.5</b> Question 11</a></li>
<li class="chapter" data-level="8.2.6" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-12-3"><i class="fa fa-check"></i><b>8.2.6</b> Question 12</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>9</b> Support Vector Machines</a><ul>
<li class="chapter" data-level="9.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#conceptual-7"><i class="fa fa-check"></i><b>9.1</b> Conceptual</a><ul>
<li class="chapter" data-level="9.1.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-1-7"><i class="fa fa-check"></i><b>9.1.1</b> Question 1</a></li>
<li class="chapter" data-level="9.1.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-2-7"><i class="fa fa-check"></i><b>9.1.2</b> Question 2</a></li>
<li class="chapter" data-level="9.1.3" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-3-7"><i class="fa fa-check"></i><b>9.1.3</b> Question 3</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#applied-7"><i class="fa fa-check"></i><b>9.2</b> Applied</a><ul>
<li class="chapter" data-level="9.2.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-4-7"><i class="fa fa-check"></i><b>9.2.1</b> Question 4</a></li>
<li class="chapter" data-level="9.2.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-5-7"><i class="fa fa-check"></i><b>9.2.2</b> Question 5</a></li>
<li class="chapter" data-level="9.2.3" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-6-7"><i class="fa fa-check"></i><b>9.2.3</b> Question 6</a></li>
<li class="chapter" data-level="9.2.4" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-7-7"><i class="fa fa-check"></i><b>9.2.4</b> Question 7</a></li>
<li class="chapter" data-level="9.2.5" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-8-7"><i class="fa fa-check"></i><b>9.2.5</b> Question 8</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="deep-learning.html"><a href="deep-learning.html"><i class="fa fa-check"></i><b>10</b> Deep Learning</a><ul>
<li class="chapter" data-level="10.1" data-path="deep-learning.html"><a href="deep-learning.html#conceptual-8"><i class="fa fa-check"></i><b>10.1</b> Conceptual</a><ul>
<li class="chapter" data-level="10.1.1" data-path="deep-learning.html"><a href="deep-learning.html#question-1-8"><i class="fa fa-check"></i><b>10.1.1</b> Question 1</a></li>
<li class="chapter" data-level="10.1.2" data-path="deep-learning.html"><a href="deep-learning.html#question-2-8"><i class="fa fa-check"></i><b>10.1.2</b> Question 2</a></li>
<li class="chapter" data-level="10.1.3" data-path="deep-learning.html"><a href="deep-learning.html#question-3-8"><i class="fa fa-check"></i><b>10.1.3</b> Question 3</a></li>
<li class="chapter" data-level="10.1.4" data-path="deep-learning.html"><a href="deep-learning.html#question-4-8"><i class="fa fa-check"></i><b>10.1.4</b> Question 4</a></li>
<li class="chapter" data-level="10.1.5" data-path="deep-learning.html"><a href="deep-learning.html#question-5-8"><i class="fa fa-check"></i><b>10.1.5</b> Question 5</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="deep-learning.html"><a href="deep-learning.html#applied-8"><i class="fa fa-check"></i><b>10.2</b> Applied</a><ul>
<li class="chapter" data-level="10.2.1" data-path="deep-learning.html"><a href="deep-learning.html#question-6-8"><i class="fa fa-check"></i><b>10.2.1</b> Question 6</a></li>
<li class="chapter" data-level="10.2.2" data-path="deep-learning.html"><a href="deep-learning.html#question-7-8"><i class="fa fa-check"></i><b>10.2.2</b> Question 7</a></li>
<li class="chapter" data-level="10.2.3" data-path="deep-learning.html"><a href="deep-learning.html#question-8-8"><i class="fa fa-check"></i><b>10.2.3</b> Question 8</a></li>
<li class="chapter" data-level="10.2.4" data-path="deep-learning.html"><a href="deep-learning.html#question-9-7"><i class="fa fa-check"></i><b>10.2.4</b> Question 9</a></li>
<li class="chapter" data-level="10.2.5" data-path="deep-learning.html"><a href="deep-learning.html#question-10-6"><i class="fa fa-check"></i><b>10.2.5</b> Question 10</a></li>
<li class="chapter" data-level="10.2.6" data-path="deep-learning.html"><a href="deep-learning.html#question-11-5"><i class="fa fa-check"></i><b>10.2.6</b> Question 11</a></li>
<li class="chapter" data-level="10.2.7" data-path="deep-learning.html"><a href="deep-learning.html#question-12-4"><i class="fa fa-check"></i><b>10.2.7</b> Question 12</a></li>
<li class="chapter" data-level="10.2.8" data-path="deep-learning.html"><a href="deep-learning.html#question-13-3"><i class="fa fa-check"></i><b>10.2.8</b> Question 13</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html"><i class="fa fa-check"></i><b>11</b> Survival Analysis and Censored Data</a><ul>
<li class="chapter" data-level="11.1" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#conceptual-9"><i class="fa fa-check"></i><b>11.1</b> Conceptual</a><ul>
<li class="chapter" data-level="11.1.1" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-1-9"><i class="fa fa-check"></i><b>11.1.1</b> Question 1</a></li>
<li class="chapter" data-level="11.1.2" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-2-9"><i class="fa fa-check"></i><b>11.1.2</b> Question 2</a></li>
<li class="chapter" data-level="11.1.3" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-3-9"><i class="fa fa-check"></i><b>11.1.3</b> Question 3</a></li>
<li class="chapter" data-level="11.1.4" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-4-9"><i class="fa fa-check"></i><b>11.1.4</b> Question 4</a></li>
<li class="chapter" data-level="11.1.5" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-5-9"><i class="fa fa-check"></i><b>11.1.5</b> Question 5</a></li>
<li class="chapter" data-level="11.1.6" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-6-9"><i class="fa fa-check"></i><b>11.1.6</b> Question 6</a></li>
<li class="chapter" data-level="11.1.7" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-7-9"><i class="fa fa-check"></i><b>11.1.7</b> Question 7</a></li>
<li class="chapter" data-level="11.1.8" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-8-9"><i class="fa fa-check"></i><b>11.1.8</b> Question 8</a></li>
<li class="chapter" data-level="11.1.9" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-9-8"><i class="fa fa-check"></i><b>11.1.9</b> Question 9</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#applied-9"><i class="fa fa-check"></i><b>11.2</b> Applied</a><ul>
<li class="chapter" data-level="11.2.1" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-10-7"><i class="fa fa-check"></i><b>11.2.1</b> Question 10</a></li>
<li class="chapter" data-level="11.2.2" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-11-6"><i class="fa fa-check"></i><b>11.2.2</b> Question 11</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html"><i class="fa fa-check"></i><b>12</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="12.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#conceptual-10"><i class="fa fa-check"></i><b>12.1</b> Conceptual</a><ul>
<li class="chapter" data-level="12.1.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-1-10"><i class="fa fa-check"></i><b>12.1.1</b> Question 1</a></li>
<li class="chapter" data-level="12.1.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-2-10"><i class="fa fa-check"></i><b>12.1.2</b> Question 2</a></li>
<li class="chapter" data-level="12.1.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-3-10"><i class="fa fa-check"></i><b>12.1.3</b> Question 3</a></li>
<li class="chapter" data-level="12.1.4" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-4-10"><i class="fa fa-check"></i><b>12.1.4</b> Question 4</a></li>
<li class="chapter" data-level="12.1.5" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-5-10"><i class="fa fa-check"></i><b>12.1.5</b> Question 5</a></li>
<li class="chapter" data-level="12.1.6" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-6-10"><i class="fa fa-check"></i><b>12.1.6</b> Question 6</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#applied-10"><i class="fa fa-check"></i><b>12.2</b> Applied</a><ul>
<li class="chapter" data-level="12.2.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-7-10"><i class="fa fa-check"></i><b>12.2.1</b> Question 7</a></li>
<li class="chapter" data-level="12.2.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-8-10"><i class="fa fa-check"></i><b>12.2.2</b> Question 8</a></li>
<li class="chapter" data-level="12.2.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-9-9"><i class="fa fa-check"></i><b>12.2.3</b> Question 9</a></li>
<li class="chapter" data-level="12.2.4" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-10-8"><i class="fa fa-check"></i><b>12.2.4</b> Question 10</a></li>
<li class="chapter" data-level="12.2.5" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-11-7"><i class="fa fa-check"></i><b>12.2.5</b> Question 11</a></li>
<li class="chapter" data-level="12.2.6" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-12-5"><i class="fa fa-check"></i><b>12.2.6</b> Question 12</a></li>
<li class="chapter" data-level="12.2.7" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-13-4"><i class="fa fa-check"></i><b>12.2.7</b> Question 13</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="multiple-testing.html"><a href="multiple-testing.html"><i class="fa fa-check"></i><b>13</b> Multiple Testing</a><ul>
<li class="chapter" data-level="13.1" data-path="multiple-testing.html"><a href="multiple-testing.html#conceptual-11"><i class="fa fa-check"></i><b>13.1</b> Conceptual</a><ul>
<li class="chapter" data-level="13.1.1" data-path="multiple-testing.html"><a href="multiple-testing.html#question-1-11"><i class="fa fa-check"></i><b>13.1.1</b> Question 1</a></li>
<li class="chapter" data-level="13.1.2" data-path="multiple-testing.html"><a href="multiple-testing.html#question-2-11"><i class="fa fa-check"></i><b>13.1.2</b> Question 2</a></li>
<li class="chapter" data-level="13.1.3" data-path="multiple-testing.html"><a href="multiple-testing.html#question-3-11"><i class="fa fa-check"></i><b>13.1.3</b> Question 3</a></li>
<li class="chapter" data-level="13.1.4" data-path="multiple-testing.html"><a href="multiple-testing.html#question-4-11"><i class="fa fa-check"></i><b>13.1.4</b> Question 4</a></li>
<li class="chapter" data-level="13.1.5" data-path="multiple-testing.html"><a href="multiple-testing.html#question-5-11"><i class="fa fa-check"></i><b>13.1.5</b> Question 5</a></li>
<li class="chapter" data-level="13.1.6" data-path="multiple-testing.html"><a href="multiple-testing.html#question-6-11"><i class="fa fa-check"></i><b>13.1.6</b> Question 6</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="multiple-testing.html"><a href="multiple-testing.html#applied-11"><i class="fa fa-check"></i><b>13.2</b> Applied</a><ul>
<li class="chapter" data-level="13.2.1" data-path="multiple-testing.html"><a href="multiple-testing.html#question-7-11"><i class="fa fa-check"></i><b>13.2.1</b> Question 7</a></li>
<li class="chapter" data-level="13.2.2" data-path="multiple-testing.html"><a href="multiple-testing.html#question-8-11"><i class="fa fa-check"></i><b>13.2.2</b> Question 8</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistical Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="deep-learning" class="section level1 hasAnchor">
<h1><span class="header-section-number">10</span> Deep Learning<a href="deep-learning.html#deep-learning" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="conceptual-8" class="section level2 hasAnchor">
<h2><span class="header-section-number">10.1</span> Conceptual<a href="deep-learning.html#conceptual-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="question-1-8" class="section level3 hasAnchor">
<h3><span class="header-section-number">10.1.1</span> Question 1<a href="deep-learning.html#question-1-8" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Consider a neural network with two hidden layers: <span class="math inline">\(p = 4\)</span> input units, 2 units
in the first hidden layer, 3 units in the second hidden layer, and a single
output.</p>
<ol style="list-style-type: lower-alpha">
<li>Draw a picture of the network, similar to Figures 10.1 or 10.4.</li>
</ol>
</blockquote>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-1"></span>
<img src="images/nn.png" alt="A nice image." width="80%" />
<p class="caption">
Figure 10.1: A nice image.
</p>
</div>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>Write out an expression for <span class="math inline">\(f(X)\)</span>, assuming ReLU activation functions. Be
as explicit as you can!</li>
</ol>
</blockquote>
<p>The three layers (from our final output layer back to the start of our network)
can be described as:</p>
<p><span class="math display">\[\begin{align*}
f(X) &amp;= g(w_{0}^{(3)} + \sum^{K_2}_{l=1} w_{l}^{(3)} A_l^{(2)}) \\
A_l^{(2)} &amp;= h_l^{(2)}(X) = g(w_{l0}^{(2)} + \sum_{k=1}^{K_1} w_{lk}^{(2)} A_k^{(1)})\\
A_k^{(1)} &amp;= h_k^{(1)}(X) = g(w_{k0}^{(1)} + \sum_{j=1}^p w_{kj}^{(1)} X_j) \\
\end{align*}\]</span></p>
<p>for <span class="math inline">\(l = 1, ..., K_2 = 3\)</span> and <span class="math inline">\(k = 1, ..., K_1 = 2\)</span> and <span class="math inline">\(p = 4\)</span>, where,</p>
<p><span class="math display">\[
g(z) = (z)_+ = \begin{cases}
  0, &amp; \text{if } z &lt; 0 \\
  z, &amp; \text{otherwise}
\end{cases}
\]</span></p>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>Now plug in some values for the coefficients and write out the value of
<span class="math inline">\(f(X)\)</span>.</li>
</ol>
</blockquote>
<p>We can perhaps achieve this most easily by fitting a real model. Note,
in the plot shown here, we also include the “bias” or intercept terms.</p>
<div class="sourceCode" id="cb685"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb685-1"><a href="deep-learning.html#cb685-1"></a><span class="kw">library</span>(ISLR2)</span>
<span id="cb685-2"><a href="deep-learning.html#cb685-2"></a><span class="kw">library</span>(neuralnet)</span>
<span id="cb685-3"><a href="deep-learning.html#cb685-3"></a><span class="kw">library</span>(sigmoid)</span>
<span id="cb685-4"><a href="deep-learning.html#cb685-4"></a><span class="kw">set.seed</span>(<span class="dv">5</span>)</span>
<span id="cb685-5"><a href="deep-learning.html#cb685-5"></a>train &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">seq_len</span>(<span class="kw">nrow</span>(ISLR2<span class="op">::</span>Boston)), <span class="kw">nrow</span>(ISLR2<span class="op">::</span>Boston) <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">/</span><span class="dv">3</span>)</span>
<span id="cb685-6"><a href="deep-learning.html#cb685-6"></a></span>
<span id="cb685-7"><a href="deep-learning.html#cb685-7"></a>net &lt;-<span class="st"> </span><span class="kw">neuralnet</span>(crim <span class="op">~</span><span class="st"> </span>lstat <span class="op">+</span><span class="st"> </span>medv <span class="op">+</span><span class="st"> </span>ptratio <span class="op">+</span><span class="st"> </span>rm,</span>
<span id="cb685-8"><a href="deep-learning.html#cb685-8"></a>    <span class="dt">data =</span> ISLR2<span class="op">::</span>Boston[train, ],</span>
<span id="cb685-9"><a href="deep-learning.html#cb685-9"></a>    <span class="dt">act.fct =</span> relu,</span>
<span id="cb685-10"><a href="deep-learning.html#cb685-10"></a>    <span class="dt">hidden =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb685-11"><a href="deep-learning.html#cb685-11"></a>)</span>
<span id="cb685-12"><a href="deep-learning.html#cb685-12"></a><span class="kw">plot</span>(net)</span></code></pre></div>
<p>We can make a prediction for a given observation using this object.</p>
<p>Firstly, let’s find an “ambiguous” test sample</p>
<div class="sourceCode" id="cb686"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb686-1"><a href="deep-learning.html#cb686-1"></a>p &lt;-<span class="st"> </span><span class="kw">predict</span>(net, ISLR2<span class="op">::</span>Boston[<span class="op">-</span>train, ])</span>
<span id="cb686-2"><a href="deep-learning.html#cb686-2"></a>x &lt;-<span class="st"> </span>ISLR2<span class="op">::</span>Boston[<span class="op">-</span>train, ][<span class="kw">which.min</span>(<span class="kw">abs</span>(p <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(<span class="kw">c</span>(<span class="kw">max</span>(p), <span class="kw">min</span>(p))))), ]</span>
<span id="cb686-3"><a href="deep-learning.html#cb686-3"></a>x &lt;-<span class="st"> </span>x[, <span class="kw">c</span>(<span class="st">&quot;lstat&quot;</span>, <span class="st">&quot;medv&quot;</span>, <span class="st">&quot;ptratio&quot;</span>, <span class="st">&quot;rm&quot;</span>)]</span>
<span id="cb686-4"><a href="deep-learning.html#cb686-4"></a><span class="kw">predict</span>(net, x)</span></code></pre></div>
<pre><code>##         [,1]
## 441 19.14392</code></pre>
<p>Or, repeating by “hand”:</p>
<div class="sourceCode" id="cb688"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb688-1"><a href="deep-learning.html#cb688-1"></a>g &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">ifelse</span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>, x, <span class="dv">0</span>) <span class="co"># relu activation function</span></span>
<span id="cb688-2"><a href="deep-learning.html#cb688-2"></a>w &lt;-<span class="st"> </span>net<span class="op">$</span>weights[[<span class="dv">1</span>]] <span class="co"># the estimated weights for each layer</span></span>
<span id="cb688-3"><a href="deep-learning.html#cb688-3"></a>v &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(x) <span class="co"># our input predictors</span></span>
<span id="cb688-4"><a href="deep-learning.html#cb688-4"></a></span>
<span id="cb688-5"><a href="deep-learning.html#cb688-5"></a><span class="co"># to calculate our prediction we can take the dot product of our predictors</span></span>
<span id="cb688-6"><a href="deep-learning.html#cb688-6"></a><span class="co"># (with 1 at the start for the bias term) and our layer weights, lw)</span></span>
<span id="cb688-7"><a href="deep-learning.html#cb688-7"></a><span class="cf">for</span> (lw <span class="cf">in</span> w) v &lt;-<span class="st"> </span><span class="kw">g</span>(<span class="kw">c</span>(<span class="dv">1</span>, v) <span class="op">%*%</span><span class="st"> </span>lw)</span>
<span id="cb688-8"><a href="deep-learning.html#cb688-8"></a>v</span></code></pre></div>
<pre><code>##          [,1]
## [1,] 19.14392</code></pre>
<blockquote>
<ol start="4" style="list-style-type: lower-alpha">
<li>How many parameters are there?</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb690"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb690-1"><a href="deep-learning.html#cb690-1"></a><span class="kw">length</span>(<span class="kw">unlist</span>(net<span class="op">$</span>weights))</span></code></pre></div>
<pre><code>## [1] 23</code></pre>
<p>There are <span class="math inline">\(4*2+2 + 2*3+3 + 3*1+1 = 23\)</span> parameters.</p>
</div>
<div id="question-2-8" class="section level3 hasAnchor">
<h3><span class="header-section-number">10.1.2</span> Question 2<a href="deep-learning.html#question-2-8" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Consider the <em>softmax</em> function in (10.13) (see also (4.13) on page 141)
for modeling multinomial probabilities.</p>
<ol style="list-style-type: lower-alpha">
<li>In (10.13), show that if we add a constant <span class="math inline">\(c\)</span> to each of the <span class="math inline">\(z_l\)</span>, then
the probability is unchanged.</li>
</ol>
</blockquote>
<p>If we add a constant <span class="math inline">\(c\)</span> to each <span class="math inline">\(Z_l\)</span> in equation 10.13 we get:</p>
<p><span class="math display">\[\begin{align*}
Pr(Y=m|X) 
 &amp;= \frac{e^{Z_m+c}}{\sum_{l=0}^9e^{Z_l+c}} \\
 &amp;= \frac{e^{Z_m}e^c}{\sum_{l=0}^9e^{Z_l}e^c} \\
 &amp;= \frac{e^{Z_m}e^c}{e^c\sum_{l=0}^9e^{Z_l}} \\
 &amp;= \frac{e^{Z_m}}{\sum_{l=0}^9e^{Z_l}} \\
\end{align*}\]</span></p>
<p>which is just equation 10.13.</p>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>In (4.13), show that if we add constants <span class="math inline">\(c_j\)</span>, <span class="math inline">\(j = 0,1,...,p\)</span>, to each of
the corresponding coefficients for each of the classes, then the predictions
at any new point <span class="math inline">\(x\)</span> are unchanged.</li>
</ol>
</blockquote>
<p>4.13 is</p>
<p><span class="math display">\[
Pr(Y=k|X=x) = \frac
{e^{\beta_{K0} + \beta_{K1}x_1 + ... + \beta_{Kp}x_p}}
{\sum_{l=1}^K e^{\beta_{l0} + \beta_{l1}x1 + ... + \beta_{lp}x_p}}
\]</span></p>
<p>adding constants <span class="math inline">\(c_j\)</span> to each class gives:</p>
<p><span class="math display">\[\begin{align*}
Pr(Y=k|X=x) 
&amp;= \frac
  {e^{\beta_{K0} + \beta_{K1}x_1 + c_1 + ... + \beta_{Kp}x_p + c_p}}
  {\sum_{l=1}^K e^{\beta_{l0} + \beta_{l1}x1 + c_1 + ... + \beta_{lp}x_p + c_p}} \\
&amp;= \frac
  {e^{c1 + ... + c_p}e^{\beta_{K0} + \beta_{K1}x_1 + ... + \beta_{Kp}x_p}}
  {\sum_{l=1}^K e^{c1 + ... + c_p}e^{\beta_{l0} + \beta_{l1}x1 + ... + \beta_{lp}x_p}} \\
&amp;= \frac
  {e^{c1 + ... + c_p}e^{\beta_{K0} + \beta_{K1}x_1 + ... + \beta_{Kp}x_p}}
  {e^{c1 + ... + c_p}\sum_{l=1}^K e^{\beta_{l0} + \beta_{l1}x1 + ... + \beta_{lp}x_p}} \\
&amp;= \frac
  {e^{\beta_{K0} + \beta_{K1}x_1 + ... + \beta_{Kp}x_p}}
  {\sum_{l=1}^K e^{\beta_{l0} + \beta_{l1}x1 + ... + \beta_{lp}x_p}} \\
\end{align*}\]</span></p>
<p>which collapses to 4.13 (with the same argument as above).</p>
<blockquote>
<p>This shows that the softmax function is <em>over-parametrized</em>. However,
regularization and SGD typically constrain the solutions so that this is not a
problem.</p>
</blockquote>
</div>
<div id="question-3-8" class="section level3 hasAnchor">
<h3><span class="header-section-number">10.1.3</span> Question 3<a href="deep-learning.html#question-3-8" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Show that the negative multinomial log-likelihood (10.14) is equivalent to
the negative log of the likelihood expression (4.5) when there are <span class="math inline">\(M = 2\)</span>
classes.</p>
</blockquote>
<p>Equation 10.14 is</p>
<p><span class="math display">\[
-\sum_{i=1}^n \sum_{m=0}^9 y_{im}\log(f_m(x_i))
\]</span></p>
<p>Equation 4.5 is:</p>
<p><span class="math display">\[
\ell(\beta_0, \beta_1) = \prod_{i:y_i=1}p(x_i) \prod_{i&#39;:y_i&#39;=0}(1-p(x_i&#39;))
\]</span></p>
<p>So, <span class="math inline">\(\log(\ell)\)</span> is:</p>
<p><span class="math display">\[\begin{align*}
\log(\ell) 
 &amp;= \log \left( \prod_{i:y_i=1}p(x_i) \prod_{i&#39;:y_i&#39;=0}(1-p(x_i&#39;)) \right ) \\
 &amp;= \sum_{i:y_1=1}\log(p(x_i)) + \sum_{i&#39;:y_i&#39;=0}\log(1-p(x_i&#39;)) \\
\end{align*}\]</span></p>
<p>If we set <span class="math inline">\(y_i\)</span> to be an indicator variable such that <span class="math inline">\(y_{i1}\)</span> and <span class="math inline">\(y_{i0}\)</span> are
1 and 0 (or 0 and 1) when our <span class="math inline">\(i\)</span>th observation is 1 (or 0) respectively, then
we can write:</p>
<p><span class="math display">\[
\log(\ell) = \sum_{i}y_{i1}\log(p(x_i)) + \sum_{i}y_{i0}\log(1-p(x_i&#39;))
\]</span></p>
<p>If we also let <span class="math inline">\(f_1(x) = p(x)\)</span> and <span class="math inline">\(f_0(x) = 1 - p(x)\)</span> then:</p>
<p><span class="math display">\[\begin{align*}
\log(\ell) 
 &amp;= \sum_i y_{i1}\log(f_1(x_i)) + \sum_{i}y_{i0}\log(f_0(x_i&#39;)) \\
 &amp;= \sum_i \sum_{m=0}^1 y_{im}\log(f_m(x_i)) \\
\end{align*}\]</span></p>
<p>When we take the negative of this, it is equivalent to 10.14 for two classes
(<span class="math inline">\(m = 0,1\)</span>).</p>
</div>
<div id="question-4-8" class="section level3 hasAnchor">
<h3><span class="header-section-number">10.1.4</span> Question 4<a href="deep-learning.html#question-4-8" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Consider a CNN that takes in <span class="math inline">\(32 \times 32\)</span> grayscale images and has a single
convolution layer with three <span class="math inline">\(5 \times 5\)</span> convolution filters (without
boundary padding).</p>
<ol style="list-style-type: lower-alpha">
<li>Draw a sketch of the input and first hidden layer similar to Figure 10.8.</li>
</ol>
</blockquote>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-6"></span>
<img src="images/nn2.png" alt="A nice image." width="50%" />
<p class="caption">
Figure 10.2: A nice image.
</p>
</div>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>How many parameters are in this model?</li>
</ol>
</blockquote>
<p>There are 5 convolution matrices each with 5x5 weights (plus 5 bias terms) to
estimate, therefore 130 parameters</p>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>Explain how this model can be thought of as an ordinary feed-forward
neural network with the individual pixels as inputs, and with constraints on
the weights in the hidden units. What are the constraints?</li>
</ol>
</blockquote>
<p>We can think of a convolution layer as a regularized fully connected layer.
The regularization in this case is due to not all inputs being connected to
all outputs, and weights being shared between connections.</p>
<p>Each output node in the convolved image can be thought of as taking inputs from
a limited number of input pixels (the neighboring pixels), with a set of
weights specified by the convolution layer which are then shared by the
connections to all other output nodes.</p>
<blockquote>
<ol start="4" style="list-style-type: lower-alpha">
<li>If there were no constraints, then how many weights would there be in the
ordinary feed-forward neural network in (c)?</li>
</ol>
</blockquote>
<p>With no constraints, we would connect each output pixel in our 5x32x32
convolution layer to each node in the 32x32 original image (plus 5 bias terms),
giving a total of 5,242,885 weights to estimate.</p>
</div>
<div id="question-5-8" class="section level3 hasAnchor">
<h3><span class="header-section-number">10.1.5</span> Question 5<a href="deep-learning.html#question-5-8" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>In Table 10.2 on page 433, we see that the ordering of the three methods with
respect to mean absolute error is different from the ordering with respect to
test set <span class="math inline">\(R^2\)</span>. How can this be?</p>
</blockquote>
<p>Mean absolute error considers <em>absolute</em> differences between predictions and
observed values, whereas <span class="math inline">\(R^2\)</span> considers the (normalized) sum of <em>squared</em>
differences, thus larger errors contribute relatively ore to <span class="math inline">\(R^2\)</span> than mean
absolute error.</p>
</div>
</div>
<div id="applied-8" class="section level2 hasAnchor">
<h2><span class="header-section-number">10.2</span> Applied<a href="deep-learning.html#applied-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="question-6-8" class="section level3 hasAnchor">
<h3><span class="header-section-number">10.2.1</span> Question 6<a href="deep-learning.html#question-6-8" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Consider the simple function <span class="math inline">\(R(\beta) = sin(\beta) + \beta/10\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li>Draw a graph of this function over the range <span class="math inline">\(\beta \in [−6, 6]\)</span>.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb692"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb692-1"><a href="deep-learning.html#cb692-1"></a>r &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">sin</span>(x) <span class="op">+</span><span class="st"> </span>x<span class="op">/</span><span class="dv">10</span></span>
<span id="cb692-2"><a href="deep-learning.html#cb692-2"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="fl">0.1</span>)</span>
<span id="cb692-3"><a href="deep-learning.html#cb692-3"></a><span class="kw">plot</span>(x, <span class="kw">r</span>(x), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</span></code></pre></div>
<p><img src="10-deep-learning_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>What is the derivative of this function?</li>
</ol>
</blockquote>
<p><span class="math display">\[
cos(x) + 1/10
\]</span></p>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>Given <span class="math inline">\(\beta^0 = 2.3\)</span>, run gradient descent to find a local minimum of
<span class="math inline">\(R(\beta)\)</span> using a learning rate of <span class="math inline">\(\rho = 0.1\)</span>. Show each of
<span class="math inline">\(\beta^0, \beta^1, ...\)</span> in your plot, as well as the final answer.</li>
</ol>
</blockquote>
<p>The derivative of our function, i.e. <span class="math inline">\(cos(x) + 1/10\)</span> gives us the gradient for
a given <span class="math inline">\(x\)</span>. For gradient descent, we move <span class="math inline">\(x\)</span> a little in the <em>opposite</em>
direction, for some learning rate <span class="math inline">\(\rho = 0.1\)</span>:</p>
<p><span class="math display">\[
x^{m+1} = x^m - \rho (cos(x^m) + 1/10)
\]</span></p>
<div class="sourceCode" id="cb693"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb693-1"><a href="deep-learning.html#cb693-1"></a>iter &lt;-<span class="st"> </span><span class="cf">function</span>(x, rho) x <span class="op">-</span><span class="st"> </span>rho<span class="op">*</span>(<span class="kw">cos</span>(x) <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">10</span>)</span>
<span id="cb693-2"><a href="deep-learning.html#cb693-2"></a>gd &lt;-<span class="st"> </span><span class="cf">function</span>(start, <span class="dt">rho =</span> <span class="fl">0.1</span>) {</span>
<span id="cb693-3"><a href="deep-learning.html#cb693-3"></a>  b &lt;-<span class="st"> </span>start</span>
<span id="cb693-4"><a href="deep-learning.html#cb693-4"></a>  v &lt;-<span class="st"> </span>b</span>
<span id="cb693-5"><a href="deep-learning.html#cb693-5"></a>  <span class="cf">while</span>(<span class="kw">abs</span>(b <span class="op">-</span><span class="st"> </span><span class="kw">iter</span>(b, <span class="fl">0.1</span>)) <span class="op">&gt;</span><span class="st"> </span><span class="fl">1e-8</span>) {</span>
<span id="cb693-6"><a href="deep-learning.html#cb693-6"></a>    b &lt;-<span class="st"> </span><span class="kw">iter</span>(b, <span class="fl">0.1</span>)</span>
<span id="cb693-7"><a href="deep-learning.html#cb693-7"></a>    v &lt;-<span class="st"> </span><span class="kw">c</span>(v, b)</span>
<span id="cb693-8"><a href="deep-learning.html#cb693-8"></a>  }</span>
<span id="cb693-9"><a href="deep-learning.html#cb693-9"></a>  v</span>
<span id="cb693-10"><a href="deep-learning.html#cb693-10"></a>}</span>
<span id="cb693-11"><a href="deep-learning.html#cb693-11"></a></span>
<span id="cb693-12"><a href="deep-learning.html#cb693-12"></a>res &lt;-<span class="st"> </span><span class="kw">gd</span>(<span class="fl">2.3</span>)</span>
<span id="cb693-13"><a href="deep-learning.html#cb693-13"></a>res[<span class="kw">length</span>(res)]</span></code></pre></div>
<pre><code>## [1] 4.612221</code></pre>
<div class="sourceCode" id="cb695"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb695-1"><a href="deep-learning.html#cb695-1"></a><span class="kw">plot</span>(x, <span class="kw">r</span>(x), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</span>
<span id="cb695-2"><a href="deep-learning.html#cb695-2"></a><span class="kw">points</span>(res, <span class="kw">r</span>(res), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">pch =</span> <span class="dv">19</span>)</span></code></pre></div>
<p><img src="10-deep-learning_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<blockquote>
<ol start="4" style="list-style-type: lower-alpha">
<li>Repeat with <span class="math inline">\(\beta^0 = 1.4\)</span>.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb696"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb696-1"><a href="deep-learning.html#cb696-1"></a>res &lt;-<span class="st"> </span><span class="kw">gd</span>(<span class="fl">1.4</span>)</span>
<span id="cb696-2"><a href="deep-learning.html#cb696-2"></a>res[<span class="kw">length</span>(res)]</span></code></pre></div>
<pre><code>## [1] -1.670964</code></pre>
<div class="sourceCode" id="cb698"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb698-1"><a href="deep-learning.html#cb698-1"></a><span class="kw">plot</span>(x, <span class="kw">r</span>(x), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</span>
<span id="cb698-2"><a href="deep-learning.html#cb698-2"></a><span class="kw">points</span>(res, <span class="kw">r</span>(res), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">pch =</span> <span class="dv">19</span>)</span></code></pre></div>
<p><img src="10-deep-learning_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
</div>
<div id="question-7-8" class="section level3 hasAnchor">
<h3><span class="header-section-number">10.2.2</span> Question 7<a href="deep-learning.html#question-7-8" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Fit a neural network to the <code>Default</code> data. Use a single hidden layer with 10
units, and dropout regularization. Have a look at Labs 10.9.1–-10.9.2 for
guidance. Compare the classification performance of your model with that of
linear logistic regression.</p>
</blockquote>
<div class="sourceCode" id="cb699"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb699-1"><a href="deep-learning.html#cb699-1"></a><span class="kw">library</span>(keras)</span>
<span id="cb699-2"><a href="deep-learning.html#cb699-2"></a></span>
<span id="cb699-3"><a href="deep-learning.html#cb699-3"></a>dat &lt;-<span class="st"> </span>ISLR2<span class="op">::</span>Boston</span>
<span id="cb699-4"><a href="deep-learning.html#cb699-4"></a>x &lt;-<span class="st"> </span><span class="kw">scale</span>(<span class="kw">model.matrix</span>(crim <span class="op">~</span><span class="st"> </span>. <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> dat))</span>
<span id="cb699-5"><a href="deep-learning.html#cb699-5"></a>n &lt;-<span class="st"> </span><span class="kw">nrow</span>(dat)</span>
<span id="cb699-6"><a href="deep-learning.html#cb699-6"></a>ntest &lt;-<span class="st"> </span><span class="kw">trunc</span>(n <span class="op">/</span><span class="st"> </span><span class="dv">3</span>)</span>
<span id="cb699-7"><a href="deep-learning.html#cb699-7"></a>testid &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span>n, ntest)</span>
<span id="cb699-8"><a href="deep-learning.html#cb699-8"></a>y &lt;-<span class="st"> </span>dat<span class="op">$</span>crim</span>
<span id="cb699-9"><a href="deep-learning.html#cb699-9"></a></span>
<span id="cb699-10"><a href="deep-learning.html#cb699-10"></a><span class="co"># logistic regression</span></span>
<span id="cb699-11"><a href="deep-learning.html#cb699-11"></a>lfit &lt;-<span class="st"> </span><span class="kw">lm</span>(crim <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> dat[<span class="op">-</span>testid, ])</span>
<span id="cb699-12"><a href="deep-learning.html#cb699-12"></a>lpred &lt;-<span class="st"> </span><span class="kw">predict</span>(lfit, dat[testid, ])</span>
<span id="cb699-13"><a href="deep-learning.html#cb699-13"></a><span class="kw">with</span>(dat[testid, ], <span class="kw">mean</span>(<span class="kw">abs</span>(lpred <span class="op">-</span><span class="st"> </span>crim)))</span></code></pre></div>
<pre><code>## [1] 2.99129</code></pre>
<div class="sourceCode" id="cb701"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb701-1"><a href="deep-learning.html#cb701-1"></a><span class="co"># keras</span></span>
<span id="cb701-2"><a href="deep-learning.html#cb701-2"></a>nn &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb701-3"><a href="deep-learning.html#cb701-3"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">10</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="dt">input_shape =</span> <span class="kw">ncol</span>(x)) <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb701-4"><a href="deep-learning.html#cb701-4"></a><span class="st">  </span><span class="kw">layer_dropout</span>(<span class="dt">rate =</span> <span class="fl">0.4</span>) <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb701-5"><a href="deep-learning.html#cb701-5"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## Loaded Tensorflow version 2.9.2</code></pre>
<div class="sourceCode" id="cb703"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb703-1"><a href="deep-learning.html#cb703-1"></a><span class="kw">compile</span>(nn, <span class="dt">loss =</span> <span class="st">&quot;mse&quot;</span>, </span>
<span id="cb703-2"><a href="deep-learning.html#cb703-2"></a>  <span class="dt">optimizer =</span> <span class="kw">optimizer_rmsprop</span>(), </span>
<span id="cb703-3"><a href="deep-learning.html#cb703-3"></a>  <span class="dt">metrics =</span> <span class="kw">list</span>(<span class="st">&quot;mean_absolute_error&quot;</span>) </span>
<span id="cb703-4"><a href="deep-learning.html#cb703-4"></a>)</span>
<span id="cb703-5"><a href="deep-learning.html#cb703-5"></a></span>
<span id="cb703-6"><a href="deep-learning.html#cb703-6"></a>history &lt;-<span class="st"> </span><span class="kw">fit</span>(nn,</span>
<span id="cb703-7"><a href="deep-learning.html#cb703-7"></a>  x[<span class="op">-</span>testid, ], y[<span class="op">-</span>testid], </span>
<span id="cb703-8"><a href="deep-learning.html#cb703-8"></a>  <span class="dt">epochs =</span> <span class="dv">100</span>, </span>
<span id="cb703-9"><a href="deep-learning.html#cb703-9"></a>  <span class="dt">batch_size =</span> <span class="dv">26</span>, </span>
<span id="cb703-10"><a href="deep-learning.html#cb703-10"></a>  <span class="dt">validation_data =</span> <span class="kw">list</span>(x[testid, ], y[testid]),</span>
<span id="cb703-11"><a href="deep-learning.html#cb703-11"></a>  <span class="dt">verbose =</span> <span class="dv">0</span></span>
<span id="cb703-12"><a href="deep-learning.html#cb703-12"></a>)</span>
<span id="cb703-13"><a href="deep-learning.html#cb703-13"></a><span class="kw">plot</span>(history, <span class="dt">smooth =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p><img src="10-deep-learning_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<div class="sourceCode" id="cb704"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb704-1"><a href="deep-learning.html#cb704-1"></a>npred &lt;-<span class="st"> </span><span class="kw">predict</span>(nn, x[testid, ])</span>
<span id="cb704-2"><a href="deep-learning.html#cb704-2"></a><span class="kw">mean</span>(<span class="kw">abs</span>(y[testid] <span class="op">-</span><span class="st"> </span>npred))</span></code></pre></div>
<pre><code>## [1] 2.239367</code></pre>
<p>In this case, the neural network outperforms logistic regression having a lower
absolute error rate on the test data.</p>
</div>
<div id="question-8-8" class="section level3 hasAnchor">
<h3><span class="header-section-number">10.2.3</span> Question 8<a href="deep-learning.html#question-8-8" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>From your collection of personal photographs, pick 10 images of animals (such
as dogs, cats, birds, farm animals, etc.). If the subject does not occupy a
reasonable part of the image, then crop the image. Now use a pretrained image
classification CNN as in Lab 10.9.4 to predict the class of each of your
images, and report the probabilities for the top five predicted classes for
each image.</p>
</blockquote>
<p><img src="images/animals/bird.jpg" /><!-- --><img src="images/animals/bird2.jpg" /><!-- --><img src="images/animals/bird3.jpg" /><!-- --><img src="images/animals/bug.jpg" /><!-- --><img src="images/animals/butterfly.jpg" /><!-- --><img src="images/animals/butterfly2.jpg" /><!-- --><img src="images/animals/elba.jpg" /><!-- --><img src="images/animals/hamish.jpg" /><!-- --><img src="images/animals/poodle.jpg" /><!-- --><img src="images/animals/tortoise.jpg" /><!-- --></p>
<div class="sourceCode" id="cb706"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb706-1"><a href="deep-learning.html#cb706-1"></a><span class="kw">library</span>(keras)</span>
<span id="cb706-2"><a href="deep-learning.html#cb706-2"></a>images &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="st">&quot;images/animals&quot;</span>)</span>
<span id="cb706-3"><a href="deep-learning.html#cb706-3"></a>x &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dt">dim =</span> <span class="kw">c</span>(<span class="kw">length</span>(images), <span class="dv">224</span>, <span class="dv">224</span>, <span class="dv">3</span>))</span>
<span id="cb706-4"><a href="deep-learning.html#cb706-4"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_len</span>(<span class="kw">length</span>(images))) {</span>
<span id="cb706-5"><a href="deep-learning.html#cb706-5"></a>  img &lt;-<span class="st"> </span><span class="kw">image_load</span>(<span class="kw">paste0</span>(<span class="st">&quot;images/animals/&quot;</span>, images[i]), <span class="dt">target_size =</span> <span class="kw">c</span>(<span class="dv">224</span>, <span class="dv">224</span>))</span>
<span id="cb706-6"><a href="deep-learning.html#cb706-6"></a>  x[i,,,] &lt;-<span class="st"> </span><span class="kw">image_to_array</span>(img)</span>
<span id="cb706-7"><a href="deep-learning.html#cb706-7"></a>}</span>
<span id="cb706-8"><a href="deep-learning.html#cb706-8"></a></span>
<span id="cb706-9"><a href="deep-learning.html#cb706-9"></a>model &lt;-<span class="st"> </span><span class="kw">application_resnet50</span>(<span class="dt">weights =</span> <span class="st">&quot;imagenet&quot;</span>)</span>
<span id="cb706-10"><a href="deep-learning.html#cb706-10"></a></span>
<span id="cb706-11"><a href="deep-learning.html#cb706-11"></a>pred &lt;-<span class="st"> </span>model <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb706-12"><a href="deep-learning.html#cb706-12"></a><span class="st">  </span><span class="kw">predict</span>(x) <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb706-13"><a href="deep-learning.html#cb706-13"></a><span class="st">  </span><span class="kw">imagenet_decode_predictions</span>(<span class="dt">top =</span> <span class="dv">5</span>)</span>
<span id="cb706-14"><a href="deep-learning.html#cb706-14"></a>  </span>
<span id="cb706-15"><a href="deep-learning.html#cb706-15"></a><span class="kw">names</span>(pred) &lt;-<span class="st"> </span>images</span>
<span id="cb706-16"><a href="deep-learning.html#cb706-16"></a><span class="kw">print</span>(pred)</span></code></pre></div>
<pre><code>## $bird.jpg
##   class_name        class_description      score
## 1  n01819313 sulphur-crested_cockatoo 0.33546346
## 2  n01580077                      jay 0.18020913
## 3  n02441942                   weasel 0.08320846
## 4  n02058221                albatross 0.07002052
## 5  n01855672                    goose 0.05195727
## 
## $bird2.jpg
##   class_name        class_description       score
## 1  n02006656                spoonbill 0.840428472
## 2  n02012849                    crane 0.016258651
## 3  n01819313 sulphur-crested_cockatoo 0.009740693
## 4  n02007558                 flamingo 0.007816133
## 5  n01667778                 terrapin 0.007497436
## 
## $bird3.jpg
##   class_name class_description        score
## 1  n01833805       hummingbird 0.9767878652
## 2  n02033041         dowitcher 0.0111253178
## 3  n02028035          redshank 0.0042763753
## 4  n02009229 little_blue_heron 0.0012727333
## 5  n02002724       black_stork 0.0008971227
## 
## $bug.jpg
##   class_name  class_description      score
## 1  n02190166                fly 0.67558432
## 2  n02167151      ground_beetle 0.10097054
## 3  n02172182        dung_beetle 0.05490898
## 4  n02169497        leaf_beetle 0.03541923
## 5  n02168699 long-horned_beetle 0.03515314
## 
## $butterfly.jpg
##   class_name class_description      score
## 1  n02951585        can_opener 0.20600472
## 2  n03476684        hair_slide 0.09360614
## 3  n04074963    remote_control 0.06316839
## 4  n02110185    Siberian_husky 0.05179002
## 5  n02123597       Siamese_cat 0.03785341
## 
## $butterfly2.jpg
##   class_name class_description        score
## 1  n02276258           admiral 9.999689e-01
## 2  n01580077               jay 1.388075e-05
## 3  n02277742           ringlet 1.235042e-05
## 4  n02279972           monarch 3.037862e-06
## 5  n02281787          lycaenid 1.261886e-06
## 
## $elba.jpg
##   class_name class_description      score
## 1  n02085620         Chihuahua 0.29891965
## 2  n02091032 Italian_greyhound 0.20332769
## 3  n02109961        Eskimo_dog 0.08477259
## 4  n02086910          papillon 0.05140292
## 5  n02110185    Siberian_husky 0.05064534
## 
## $hamish.jpg
##   class_name   class_description       score
## 1  n02097209  standard_schnauzer 0.636144340
## 2  n02097047 miniature_schnauzer 0.345085502
## 3  n02097130     giant_schnauzer 0.016421758
## 4  n02097298      Scotch_terrier 0.001911599
## 5  n02096177               cairn 0.000205432
## 
## $poodle.jpg
##   class_name   class_description       score
## 1  n02113799     standard_poodle 0.829671025
## 2  n02088094        Afghan_hound 0.074567847
## 3  n02113712    miniature_poodle 0.032005541
## 4  n02102973 Irish_water_spaniel 0.018583138
## 5  n02102318      cocker_spaniel 0.008629773
## 
## $tortoise.jpg
##   class_name class_description      score
## 1  n04033995             quilt 0.28395891
## 2  n02110958               pug 0.15959547
## 3  n03188531            diaper 0.14018108
## 4  n02108915    French_bulldog 0.09364159
## 5  n04235860      sleeping_bag 0.02608400</code></pre>
</div>
<div id="question-9-7" class="section level3 hasAnchor">
<h3><span class="header-section-number">10.2.4</span> Question 9<a href="deep-learning.html#question-9-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Fit a lag-5 autoregressive model to the <code>NYSE</code> data, as described in the text
and Lab 10.9.6. Refit the model with a 12-level factor representing the
month. Does this factor improve the performance of the model?</p>
</blockquote>
<p>Fitting the model as described in the text.</p>
<div class="sourceCode" id="cb708"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb708-1"><a href="deep-learning.html#cb708-1"></a><span class="kw">library</span>(tidyverse)</span></code></pre></div>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
## ✔ ggplot2 3.3.6      ✔ purrr   0.3.5 
## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
## ✔ tidyr   1.2.1      ✔ stringr 1.4.1 
## ✔ readr   2.1.3      ✔ forcats 0.5.2 
## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::compute() masks neuralnet::compute()
## ✖ dplyr::filter()  masks stats::filter()
## ✖ dplyr::lag()     masks stats::lag()</code></pre>
<div class="sourceCode" id="cb710"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb710-1"><a href="deep-learning.html#cb710-1"></a><span class="kw">library</span>(ISLR2)</span>
<span id="cb710-2"><a href="deep-learning.html#cb710-2"></a>xdata &lt;-<span class="st"> </span><span class="kw">data.matrix</span>(NYSE[, <span class="kw">c</span>(<span class="st">&quot;DJ_return&quot;</span>, <span class="st">&quot;log_volume&quot;</span>,<span class="st">&quot;log_volatility&quot;</span>)])</span>
<span id="cb710-3"><a href="deep-learning.html#cb710-3"></a>istrain &lt;-<span class="st"> </span>NYSE[, <span class="st">&quot;train&quot;</span>]</span>
<span id="cb710-4"><a href="deep-learning.html#cb710-4"></a>xdata &lt;-<span class="st"> </span><span class="kw">scale</span>(xdata)</span>
<span id="cb710-5"><a href="deep-learning.html#cb710-5"></a></span>
<span id="cb710-6"><a href="deep-learning.html#cb710-6"></a>lagm &lt;-<span class="st"> </span><span class="cf">function</span>(x, <span class="dt">k =</span> <span class="dv">1</span>) {</span>
<span id="cb710-7"><a href="deep-learning.html#cb710-7"></a>  n &lt;-<span class="st"> </span><span class="kw">nrow</span>(x)</span>
<span id="cb710-8"><a href="deep-learning.html#cb710-8"></a>  pad &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, k, <span class="kw">ncol</span>(x))</span>
<span id="cb710-9"><a href="deep-learning.html#cb710-9"></a>  <span class="kw">rbind</span>(pad, x[<span class="dv">1</span><span class="op">:</span>(n <span class="op">-</span><span class="st"> </span>k), ])</span>
<span id="cb710-10"><a href="deep-learning.html#cb710-10"></a>}</span>
<span id="cb710-11"><a href="deep-learning.html#cb710-11"></a></span>
<span id="cb710-12"><a href="deep-learning.html#cb710-12"></a>arframe &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb710-13"><a href="deep-learning.html#cb710-13"></a>  <span class="dt">log_volume =</span> xdata[, <span class="st">&quot;log_volume&quot;</span>], </span>
<span id="cb710-14"><a href="deep-learning.html#cb710-14"></a>  <span class="dt">L1 =</span> <span class="kw">lagm</span>(xdata, <span class="dv">1</span>), </span>
<span id="cb710-15"><a href="deep-learning.html#cb710-15"></a>  <span class="dt">L2 =</span> <span class="kw">lagm</span>(xdata, <span class="dv">2</span>),</span>
<span id="cb710-16"><a href="deep-learning.html#cb710-16"></a>  <span class="dt">L3 =</span> <span class="kw">lagm</span>(xdata, <span class="dv">3</span>),</span>
<span id="cb710-17"><a href="deep-learning.html#cb710-17"></a>  <span class="dt">L4 =</span> <span class="kw">lagm</span>(xdata, <span class="dv">4</span>),</span>
<span id="cb710-18"><a href="deep-learning.html#cb710-18"></a>  <span class="dt">L5 =</span> <span class="kw">lagm</span>(xdata, <span class="dv">5</span>)</span>
<span id="cb710-19"><a href="deep-learning.html#cb710-19"></a>)</span>
<span id="cb710-20"><a href="deep-learning.html#cb710-20"></a></span>
<span id="cb710-21"><a href="deep-learning.html#cb710-21"></a>arframe &lt;-<span class="st"> </span>arframe[<span class="op">-</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>), ]</span>
<span id="cb710-22"><a href="deep-learning.html#cb710-22"></a>istrain &lt;-<span class="st"> </span>istrain[<span class="op">-</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>)]</span>
<span id="cb710-23"><a href="deep-learning.html#cb710-23"></a></span>
<span id="cb710-24"><a href="deep-learning.html#cb710-24"></a>arfit &lt;-<span class="st"> </span><span class="kw">lm</span>(log_volume <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> arframe[istrain, ])</span>
<span id="cb710-25"><a href="deep-learning.html#cb710-25"></a>arpred &lt;-<span class="st"> </span><span class="kw">predict</span>(arfit, arframe[<span class="op">!</span>istrain, ])</span>
<span id="cb710-26"><a href="deep-learning.html#cb710-26"></a>V0 &lt;-<span class="st"> </span><span class="kw">var</span>(arframe[<span class="op">!</span>istrain, <span class="st">&quot;log_volume&quot;</span>])</span>
<span id="cb710-27"><a href="deep-learning.html#cb710-27"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>((arpred <span class="op">-</span><span class="st"> </span>arframe[<span class="op">!</span>istrain, <span class="st">&quot;log_volume&quot;</span>])<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>V0</span></code></pre></div>
<pre><code>## [1] 0.413223</code></pre>
<p>Now we add month (and work with tidyverse).</p>
<div class="sourceCode" id="cb712"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb712-1"><a href="deep-learning.html#cb712-1"></a>arframe<span class="op">$</span>month =<span class="st"> </span><span class="kw">as.factor</span>(<span class="kw">str_match</span>(NYSE<span class="op">$</span>date, <span class="st">&quot;-(</span><span class="ch">\\</span><span class="st">d+)-&quot;</span>)[,<span class="dv">2</span>])[<span class="op">-</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>)]</span>
<span id="cb712-2"><a href="deep-learning.html#cb712-2"></a>arfit2 &lt;-<span class="st"> </span><span class="kw">lm</span>(log_volume <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> arframe[istrain, ])</span>
<span id="cb712-3"><a href="deep-learning.html#cb712-3"></a>arpred2 &lt;-<span class="st"> </span><span class="kw">predict</span>(arfit2, arframe[<span class="op">!</span>istrain, ])</span>
<span id="cb712-4"><a href="deep-learning.html#cb712-4"></a>V0 &lt;-<span class="st"> </span><span class="kw">var</span>(arframe[<span class="op">!</span>istrain, <span class="st">&quot;log_volume&quot;</span>])</span>
<span id="cb712-5"><a href="deep-learning.html#cb712-5"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>((arpred2 <span class="op">-</span><span class="st"> </span>arframe[<span class="op">!</span>istrain, <span class="st">&quot;log_volume&quot;</span>])<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>V0</span></code></pre></div>
<pre><code>## [1] 0.4170418</code></pre>
<p>Adding month as a factor marginally improves the <span class="math inline">\(R^2\)</span> of our model (from
0.413223 to 0.4170418). This is a significant improvement in fit and model
2 has a lower AIC.</p>
<div class="sourceCode" id="cb714"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb714-1"><a href="deep-learning.html#cb714-1"></a><span class="kw">anova</span>(arfit, arfit2)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: log_volume ~ L1.DJ_return + L1.log_volume + L1.log_volatility + 
##     L2.DJ_return + L2.log_volume + L2.log_volatility + L3.DJ_return + 
##     L3.log_volume + L3.log_volatility + L4.DJ_return + L4.log_volume + 
##     L4.log_volatility + L5.DJ_return + L5.log_volume + L5.log_volatility
## Model 2: log_volume ~ L1.DJ_return + L1.log_volume + L1.log_volatility + 
##     L2.DJ_return + L2.log_volume + L2.log_volatility + L3.DJ_return + 
##     L3.log_volume + L3.log_volatility + L4.DJ_return + L4.log_volume + 
##     L4.log_volatility + L5.DJ_return + L5.log_volume + L5.log_volatility + 
##     month
##   Res.Df    RSS Df Sum of Sq      F   Pr(&gt;F)    
## 1   4260 1791.0                                 
## 2   4249 1775.8 11    15.278 3.3234 0.000143 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb716"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb716-1"><a href="deep-learning.html#cb716-1"></a><span class="kw">AIC</span>(arfit, arfit2)</span></code></pre></div>
<pre><code>##        df      AIC
## arfit  17 8447.663
## arfit2 28 8433.031</code></pre>
</div>
<div id="question-10-6" class="section level3 hasAnchor">
<h3><span class="header-section-number">10.2.5</span> Question 10<a href="deep-learning.html#question-10-6" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>In Section 10.9.6, we showed how to fit a linear AR model to the <code>NYSE</code> data
using the <code>lm()</code> function. However, we also mentioned that we can “flatten”
the short sequences produced for the RNN model in order to fit a linear AR
model. Use this latter approach to fit a linear AR model to the NYSE data.
Compare the test <span class="math inline">\(R^2\)</span> of this linear AR model to that of the linear AR model
that we fit in the lab. What are the advantages/disadvantages of each
approach?</p>
</blockquote>
<p>The <code>lm</code> model is the same as that fit above:</p>
<div class="sourceCode" id="cb718"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb718-1"><a href="deep-learning.html#cb718-1"></a>arfit &lt;-<span class="st"> </span><span class="kw">lm</span>(log_volume <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> arframe[istrain, ])</span>
<span id="cb718-2"><a href="deep-learning.html#cb718-2"></a>arpred &lt;-<span class="st"> </span><span class="kw">predict</span>(arfit, arframe[<span class="op">!</span>istrain, ])</span>
<span id="cb718-3"><a href="deep-learning.html#cb718-3"></a>V0 &lt;-<span class="st"> </span><span class="kw">var</span>(arframe[<span class="op">!</span>istrain, <span class="st">&quot;log_volume&quot;</span>])</span>
<span id="cb718-4"><a href="deep-learning.html#cb718-4"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>((arpred <span class="op">-</span><span class="st"> </span>arframe[<span class="op">!</span>istrain, <span class="st">&quot;log_volume&quot;</span>])<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>V0</span></code></pre></div>
<pre><code>## [1] 0.4170418</code></pre>
<p>Now we reshape the data for the RNN</p>
<div class="sourceCode" id="cb720"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb720-1"><a href="deep-learning.html#cb720-1"></a>n &lt;-<span class="st"> </span><span class="kw">nrow</span>(arframe)</span>
<span id="cb720-2"><a href="deep-learning.html#cb720-2"></a>xrnn &lt;-<span class="st"> </span><span class="kw">data.matrix</span>(arframe[, <span class="dv">-1</span>])</span>
<span id="cb720-3"><a href="deep-learning.html#cb720-3"></a>xrnn &lt;-<span class="st"> </span><span class="kw">array</span>(xrnn, <span class="kw">c</span>(n, <span class="dv">3</span>, <span class="dv">5</span>))</span>
<span id="cb720-4"><a href="deep-learning.html#cb720-4"></a>xrnn &lt;-<span class="st"> </span>xrnn[, , <span class="dv">5</span><span class="op">:</span><span class="dv">1</span>]</span>
<span id="cb720-5"><a href="deep-learning.html#cb720-5"></a>xrnn &lt;-<span class="st"> </span><span class="kw">aperm</span>(xrnn, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>))</span></code></pre></div>
<p>We can add a “flatten” layer to turn the reshaped data into a long vector of
predictors resulting in a linear AR model.</p>
<div class="sourceCode" id="cb721"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb721-1"><a href="deep-learning.html#cb721-1"></a>model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb721-2"><a href="deep-learning.html#cb721-2"></a><span class="st">  </span><span class="kw">layer_flatten</span>(<span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">3</span>)) <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb721-3"><a href="deep-learning.html#cb721-3"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>Now let’s fit this model.</p>
<div class="sourceCode" id="cb722"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb722-1"><a href="deep-learning.html#cb722-1"></a>model <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb722-2"><a href="deep-learning.html#cb722-2"></a><span class="st">  </span><span class="kw">compile</span>(<span class="dt">optimizer =</span> <span class="kw">optimizer_rmsprop</span>(), <span class="dt">loss =</span> <span class="st">&quot;mse&quot;</span>)</span>
<span id="cb722-3"><a href="deep-learning.html#cb722-3"></a></span>
<span id="cb722-4"><a href="deep-learning.html#cb722-4"></a>history &lt;-<span class="st"> </span>model <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb722-5"><a href="deep-learning.html#cb722-5"></a><span class="st">  </span><span class="kw">fit</span>(</span>
<span id="cb722-6"><a href="deep-learning.html#cb722-6"></a>    xrnn[istrain,, ],</span>
<span id="cb722-7"><a href="deep-learning.html#cb722-7"></a>    arframe[istrain, <span class="st">&quot;log_volume&quot;</span>],</span>
<span id="cb722-8"><a href="deep-learning.html#cb722-8"></a>    <span class="dt">batch_size =</span> <span class="dv">64</span>,</span>
<span id="cb722-9"><a href="deep-learning.html#cb722-9"></a>    <span class="dt">epochs =</span> <span class="dv">200</span>,</span>
<span id="cb722-10"><a href="deep-learning.html#cb722-10"></a>    <span class="dt">validation_data =</span> <span class="kw">list</span>(xrnn[<span class="op">!</span>istrain,, ], arframe[<span class="op">!</span>istrain, <span class="st">&quot;log_volume&quot;</span>]),</span>
<span id="cb722-11"><a href="deep-learning.html#cb722-11"></a>    <span class="dt">verbose =</span> <span class="dv">0</span></span>
<span id="cb722-12"><a href="deep-learning.html#cb722-12"></a>  )</span>
<span id="cb722-13"><a href="deep-learning.html#cb722-13"></a></span>
<span id="cb722-14"><a href="deep-learning.html#cb722-14"></a><span class="kw">plot</span>(history, <span class="dt">smooth =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p><img src="10-deep-learning_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<div class="sourceCode" id="cb723"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb723-1"><a href="deep-learning.html#cb723-1"></a>kpred &lt;-<span class="st"> </span><span class="kw">predict</span>(model, xrnn[<span class="op">!</span>istrain,, ])</span>
<span id="cb723-2"><a href="deep-learning.html#cb723-2"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>((kpred <span class="op">-</span><span class="st"> </span>arframe[<span class="op">!</span>istrain, <span class="st">&quot;log_volume&quot;</span>])<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>V0</span></code></pre></div>
<pre><code>## [1] 0.4120764</code></pre>
<p>Both models estimate the same number of coefficients/weights (16):</p>
<div class="sourceCode" id="cb725"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb725-1"><a href="deep-learning.html#cb725-1"></a><span class="kw">coef</span>(arfit)</span></code></pre></div>
<pre><code>##       (Intercept)      L1.DJ_return     L1.log_volume L1.log_volatility 
##       0.067916689       0.094410214       0.498673056       0.586274266 
##      L2.DJ_return     L2.log_volume L2.log_volatility      L3.DJ_return 
##      -0.027299158       0.036903027      -0.931509135       0.037995916 
##     L3.log_volume L3.log_volatility      L4.DJ_return     L4.log_volume 
##       0.070312741       0.216160520      -0.004954842       0.117079461 
## L4.log_volatility      L5.DJ_return     L5.log_volume L5.log_volatility 
##      -0.039752786      -0.029620296       0.096034795       0.144510264 
##           month02           month03           month04           month05 
##      -0.100003367      -0.143781381      -0.028242819      -0.131120579 
##           month06           month07           month08           month09 
##      -0.125993911      -0.141608808      -0.163030102      -0.018889698 
##           month10           month11           month12 
##      -0.017206826      -0.037298183       0.008361380</code></pre>
<div class="sourceCode" id="cb727"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb727-1"><a href="deep-learning.html#cb727-1"></a>model<span class="op">$</span><span class="kw">get_weights</span>()</span></code></pre></div>
<pre><code>## [[1]]
##               [,1]
##  [1,] -0.030247919
##  [2,]  0.101361901
##  [3,]  0.124982111
##  [4,] -0.006559406
##  [5,]  0.117189959
##  [6,]  0.053089373
##  [7,]  0.038364843
##  [8,]  0.081733100
##  [9,]  0.045528077
## [10,] -0.026259480
## [11,]  0.032308374
## [12,] -0.731617033
## [13,]  0.094153978
## [14,]  0.508704364
## [15,]  0.479608297
## 
## [[2]]
## [1] -0.008595592</code></pre>
<p>The flattened RNN has a lower <span class="math inline">\(R^2\)</span> on the test data than our <code>lm</code> model
above. The <code>lm</code> model is quicker to fit and conceptually simpler also
giving us the ability to inspect the coefficients for different variables.</p>
<p>The flattened RNN is regularized to some extent as data are processed in
batches.</p>
</div>
<div id="question-11-5" class="section level3 hasAnchor">
<h3><span class="header-section-number">10.2.6</span> Question 11<a href="deep-learning.html#question-11-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Repeat the previous exercise, but now fit a nonlinear AR model by “flattening”
the short sequences produced for the RNN model.</p>
</blockquote>
<p>From the book:</p>
<blockquote>
<p>To fit a nonlinear AR model, we could add in a hidden layer.</p>
</blockquote>
<div class="sourceCode" id="cb729"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb729-1"><a href="deep-learning.html#cb729-1"></a>xfun<span class="op">::</span><span class="kw">cache_rds</span>({</span>
<span id="cb729-2"><a href="deep-learning.html#cb729-2"></a></span>
<span id="cb729-3"><a href="deep-learning.html#cb729-3"></a>  model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">|</span><span class="er">&gt;</span><span class="st"> </span></span>
<span id="cb729-4"><a href="deep-learning.html#cb729-4"></a><span class="st">    </span><span class="kw">layer_flatten</span>(<span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">3</span>)) <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb729-5"><a href="deep-learning.html#cb729-5"></a><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">32</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb729-6"><a href="deep-learning.html#cb729-6"></a><span class="st">    </span><span class="kw">layer_dropout</span>(<span class="dt">rate =</span> <span class="fl">0.4</span>) <span class="op">|</span><span class="er">&gt;</span><span class="st"> </span></span>
<span id="cb729-7"><a href="deep-learning.html#cb729-7"></a><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">1</span>)</span>
<span id="cb729-8"><a href="deep-learning.html#cb729-8"></a></span>
<span id="cb729-9"><a href="deep-learning.html#cb729-9"></a>  model <span class="op">|</span><span class="er">&gt;</span><span class="st"> </span><span class="kw">compile</span>(</span>
<span id="cb729-10"><a href="deep-learning.html#cb729-10"></a>    <span class="dt">loss =</span> <span class="st">&quot;mse&quot;</span>, </span>
<span id="cb729-11"><a href="deep-learning.html#cb729-11"></a>    <span class="dt">optimizer =</span> <span class="kw">optimizer_rmsprop</span>(), </span>
<span id="cb729-12"><a href="deep-learning.html#cb729-12"></a>    <span class="dt">metrics =</span> <span class="st">&quot;mse&quot;</span></span>
<span id="cb729-13"><a href="deep-learning.html#cb729-13"></a>  )</span>
<span id="cb729-14"><a href="deep-learning.html#cb729-14"></a></span>
<span id="cb729-15"><a href="deep-learning.html#cb729-15"></a>  history &lt;-<span class="st"> </span>model <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb729-16"><a href="deep-learning.html#cb729-16"></a><span class="st">    </span><span class="kw">fit</span>(</span>
<span id="cb729-17"><a href="deep-learning.html#cb729-17"></a>      xrnn[istrain,, ],</span>
<span id="cb729-18"><a href="deep-learning.html#cb729-18"></a>      arframe[istrain, <span class="st">&quot;log_volume&quot;</span>],</span>
<span id="cb729-19"><a href="deep-learning.html#cb729-19"></a>      <span class="dt">batch_size =</span> <span class="dv">64</span>,</span>
<span id="cb729-20"><a href="deep-learning.html#cb729-20"></a>      <span class="dt">epochs =</span> <span class="dv">200</span>,</span>
<span id="cb729-21"><a href="deep-learning.html#cb729-21"></a>      <span class="dt">validation_data =</span> <span class="kw">list</span>(xrnn[<span class="op">!</span>istrain,, ], arframe[<span class="op">!</span>istrain, <span class="st">&quot;log_volume&quot;</span>]),</span>
<span id="cb729-22"><a href="deep-learning.html#cb729-22"></a>      <span class="dt">verbose =</span> <span class="dv">0</span></span>
<span id="cb729-23"><a href="deep-learning.html#cb729-23"></a>    )</span>
<span id="cb729-24"><a href="deep-learning.html#cb729-24"></a></span>
<span id="cb729-25"><a href="deep-learning.html#cb729-25"></a>  <span class="kw">plot</span>(history, <span class="dt">smooth =</span> <span class="ot">FALSE</span>, <span class="dt">metrics =</span> <span class="st">&quot;mse&quot;</span>)</span>
<span id="cb729-26"><a href="deep-learning.html#cb729-26"></a>  kpred &lt;-<span class="st"> </span><span class="kw">predict</span>(model, xrnn[<span class="op">!</span>istrain,, ])</span>
<span id="cb729-27"><a href="deep-learning.html#cb729-27"></a>  <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>((kpred <span class="op">-</span><span class="st"> </span>arframe[<span class="op">!</span>istrain, <span class="st">&quot;log_volume&quot;</span>])<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>V0</span>
<span id="cb729-28"><a href="deep-learning.html#cb729-28"></a></span>
<span id="cb729-29"><a href="deep-learning.html#cb729-29"></a>})</span></code></pre></div>
<pre><code>## [1] 0.4246722</code></pre>
<p>This approach improves our <span class="math inline">\(R^2\)</span> over the linear model above.</p>
</div>
<div id="question-12-4" class="section level3 hasAnchor">
<h3><span class="header-section-number">10.2.7</span> Question 12<a href="deep-learning.html#question-12-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Consider the RNN fit to the <code>NYSE</code> data in Section 10.9.6. Modify the code to
allow inclusion of the variable <code>day_of_week</code>, and fit the RNN. Compute the
test <span class="math inline">\(R^2\)</span>.</p>
</blockquote>
<p>To accomplish this, I’ll include day of the week as one of the lagged variables
in the RNN. Thus, our input for each observation will be 4 x 5 (rather than
3 x 5).</p>
<div class="sourceCode" id="cb731"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb731-1"><a href="deep-learning.html#cb731-1"></a>xfun<span class="op">::</span><span class="kw">cache_rds</span>({</span>
<span id="cb731-2"><a href="deep-learning.html#cb731-2"></a>  xdata &lt;-<span class="st"> </span><span class="kw">data.matrix</span>(</span>
<span id="cb731-3"><a href="deep-learning.html#cb731-3"></a>    NYSE[, <span class="kw">c</span>(<span class="st">&quot;day_of_week&quot;</span>, <span class="st">&quot;DJ_return&quot;</span>, <span class="st">&quot;log_volume&quot;</span>,<span class="st">&quot;log_volatility&quot;</span>)] </span>
<span id="cb731-4"><a href="deep-learning.html#cb731-4"></a>  )</span>
<span id="cb731-5"><a href="deep-learning.html#cb731-5"></a>  istrain &lt;-<span class="st"> </span>NYSE[, <span class="st">&quot;train&quot;</span>]</span>
<span id="cb731-6"><a href="deep-learning.html#cb731-6"></a>  xdata &lt;-<span class="st"> </span><span class="kw">scale</span>(xdata)</span>
<span id="cb731-7"><a href="deep-learning.html#cb731-7"></a></span>
<span id="cb731-8"><a href="deep-learning.html#cb731-8"></a>  arframe &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb731-9"><a href="deep-learning.html#cb731-9"></a>    <span class="dt">log_volume =</span> xdata[, <span class="st">&quot;log_volume&quot;</span>], </span>
<span id="cb731-10"><a href="deep-learning.html#cb731-10"></a>    <span class="dt">L1 =</span> <span class="kw">lagm</span>(xdata, <span class="dv">1</span>),</span>
<span id="cb731-11"><a href="deep-learning.html#cb731-11"></a>    <span class="dt">L2 =</span> <span class="kw">lagm</span>(xdata, <span class="dv">2</span>),</span>
<span id="cb731-12"><a href="deep-learning.html#cb731-12"></a>    <span class="dt">L3 =</span> <span class="kw">lagm</span>(xdata, <span class="dv">3</span>), </span>
<span id="cb731-13"><a href="deep-learning.html#cb731-13"></a>    <span class="dt">L4 =</span> <span class="kw">lagm</span>(xdata, <span class="dv">4</span>),</span>
<span id="cb731-14"><a href="deep-learning.html#cb731-14"></a>    <span class="dt">L5 =</span> <span class="kw">lagm</span>(xdata, <span class="dv">5</span>)</span>
<span id="cb731-15"><a href="deep-learning.html#cb731-15"></a>  )</span>
<span id="cb731-16"><a href="deep-learning.html#cb731-16"></a>  arframe &lt;-<span class="st"> </span>arframe[<span class="op">-</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>), ]</span>
<span id="cb731-17"><a href="deep-learning.html#cb731-17"></a>  istrain &lt;-<span class="st"> </span>istrain[<span class="op">-</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>)]</span>
<span id="cb731-18"><a href="deep-learning.html#cb731-18"></a></span>
<span id="cb731-19"><a href="deep-learning.html#cb731-19"></a>  n &lt;-<span class="st"> </span><span class="kw">nrow</span>(arframe)</span>
<span id="cb731-20"><a href="deep-learning.html#cb731-20"></a>  xrnn &lt;-<span class="st"> </span><span class="kw">data.matrix</span>(arframe[, <span class="dv">-1</span>])</span>
<span id="cb731-21"><a href="deep-learning.html#cb731-21"></a>  xrnn &lt;-<span class="st"> </span><span class="kw">array</span>(xrnn, <span class="kw">c</span>(n, <span class="dv">4</span>, <span class="dv">5</span>))</span>
<span id="cb731-22"><a href="deep-learning.html#cb731-22"></a>  xrnn &lt;-<span class="st"> </span>xrnn[,, <span class="dv">5</span><span class="op">:</span><span class="dv">1</span>]</span>
<span id="cb731-23"><a href="deep-learning.html#cb731-23"></a>  xrnn &lt;-<span class="st"> </span><span class="kw">aperm</span>(xrnn, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>))</span>
<span id="cb731-24"><a href="deep-learning.html#cb731-24"></a>  <span class="kw">dim</span>(xrnn)</span>
<span id="cb731-25"><a href="deep-learning.html#cb731-25"></a></span>
<span id="cb731-26"><a href="deep-learning.html#cb731-26"></a>  model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb731-27"><a href="deep-learning.html#cb731-27"></a><span class="st">      </span><span class="kw">layer_simple_rnn</span>(<span class="dt">units =</span> <span class="dv">12</span>,</span>
<span id="cb731-28"><a href="deep-learning.html#cb731-28"></a>      <span class="dt">input_shape =</span> <span class="kw">list</span>(<span class="dv">5</span>, <span class="dv">4</span>),</span>
<span id="cb731-29"><a href="deep-learning.html#cb731-29"></a>      <span class="dt">dropout =</span> <span class="fl">0.1</span>, </span>
<span id="cb731-30"><a href="deep-learning.html#cb731-30"></a>      <span class="dt">recurrent_dropout =</span> <span class="fl">0.1</span></span>
<span id="cb731-31"><a href="deep-learning.html#cb731-31"></a>    ) <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb731-32"><a href="deep-learning.html#cb731-32"></a><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">1</span>)</span>
<span id="cb731-33"><a href="deep-learning.html#cb731-33"></a></span>
<span id="cb731-34"><a href="deep-learning.html#cb731-34"></a>  model <span class="op">|</span><span class="er">&gt;</span><span class="st"> </span><span class="kw">compile</span>(<span class="dt">optimizer =</span> <span class="kw">optimizer_rmsprop</span>(), <span class="dt">loss =</span> <span class="st">&quot;mse&quot;</span>)</span>
<span id="cb731-35"><a href="deep-learning.html#cb731-35"></a></span>
<span id="cb731-36"><a href="deep-learning.html#cb731-36"></a>  history &lt;-<span class="st"> </span>model <span class="op">|</span><span class="er">&gt;</span><span class="st"> </span></span>
<span id="cb731-37"><a href="deep-learning.html#cb731-37"></a><span class="st">    </span><span class="kw">fit</span>(</span>
<span id="cb731-38"><a href="deep-learning.html#cb731-38"></a>      xrnn[istrain,, ],</span>
<span id="cb731-39"><a href="deep-learning.html#cb731-39"></a>      arframe[istrain, <span class="st">&quot;log_volume&quot;</span>],</span>
<span id="cb731-40"><a href="deep-learning.html#cb731-40"></a>      <span class="dt">batch_size =</span> <span class="dv">64</span>,</span>
<span id="cb731-41"><a href="deep-learning.html#cb731-41"></a>      <span class="dt">epochs =</span> <span class="dv">200</span>,</span>
<span id="cb731-42"><a href="deep-learning.html#cb731-42"></a>      <span class="dt">validation_data =</span> <span class="kw">list</span>(xrnn[<span class="op">!</span>istrain,, ], arframe[<span class="op">!</span>istrain, <span class="st">&quot;log_volume&quot;</span>]),</span>
<span id="cb731-43"><a href="deep-learning.html#cb731-43"></a>      <span class="dt">verbose =</span> <span class="dv">0</span></span>
<span id="cb731-44"><a href="deep-learning.html#cb731-44"></a>  )</span>
<span id="cb731-45"><a href="deep-learning.html#cb731-45"></a></span>
<span id="cb731-46"><a href="deep-learning.html#cb731-46"></a>  kpred &lt;-<span class="st"> </span><span class="kw">predict</span>(model, xrnn[<span class="op">!</span>istrain,, ])</span>
<span id="cb731-47"><a href="deep-learning.html#cb731-47"></a>  <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>((kpred <span class="op">-</span><span class="st"> </span>arframe[<span class="op">!</span>istrain, <span class="st">&quot;log_volume&quot;</span>])<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>V0</span>
<span id="cb731-48"><a href="deep-learning.html#cb731-48"></a></span>
<span id="cb731-49"><a href="deep-learning.html#cb731-49"></a>})</span></code></pre></div>
<pre><code>## [1] 0.447159</code></pre>
</div>
<div id="question-13-3" class="section level3 hasAnchor">
<h3><span class="header-section-number">10.2.8</span> Question 13<a href="deep-learning.html#question-13-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Repeat the analysis of Lab 10.9.5 on the <code>IMDb</code> data using a similarly
structured neural network. There we used a dictionary of size 10,000. Consider
the effects of varying the dictionary size. Try the values 1000, 3000, 5000,
and 10,000, and compare the results.</p>
</blockquote>
<div class="sourceCode" id="cb733"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb733-1"><a href="deep-learning.html#cb733-1"></a>xfun<span class="op">::</span><span class="kw">cache_rds</span>({</span>
<span id="cb733-2"><a href="deep-learning.html#cb733-2"></a>  <span class="kw">library</span>(knitr)</span>
<span id="cb733-3"><a href="deep-learning.html#cb733-3"></a>  accuracy &lt;-<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb733-4"><a href="deep-learning.html#cb733-4"></a>  <span class="cf">for</span>(max_features <span class="cf">in</span> <span class="kw">c</span>(<span class="dv">1000</span>, <span class="dv">3000</span>, <span class="dv">5000</span>, <span class="dv">10000</span>)) {</span>
<span id="cb733-5"><a href="deep-learning.html#cb733-5"></a>    imdb &lt;-<span class="st"> </span><span class="kw">dataset_imdb</span>(<span class="dt">num_words =</span> max_features)</span>
<span id="cb733-6"><a href="deep-learning.html#cb733-6"></a>    <span class="kw">c</span>(<span class="kw">c</span>(x_train, y_train), <span class="kw">c</span>(x_test, y_test)) <span class="op">%&lt;-%</span><span class="st"> </span>imdb</span>
<span id="cb733-7"><a href="deep-learning.html#cb733-7"></a></span>
<span id="cb733-8"><a href="deep-learning.html#cb733-8"></a>    maxlen &lt;-<span class="st"> </span><span class="dv">500</span></span>
<span id="cb733-9"><a href="deep-learning.html#cb733-9"></a>    x_train &lt;-<span class="st"> </span><span class="kw">pad_sequences</span>(x_train, <span class="dt">maxlen =</span> maxlen)</span>
<span id="cb733-10"><a href="deep-learning.html#cb733-10"></a>    x_test &lt;-<span class="st"> </span><span class="kw">pad_sequences</span>(x_test, <span class="dt">maxlen =</span> maxlen)</span>
<span id="cb733-11"><a href="deep-learning.html#cb733-11"></a></span>
<span id="cb733-12"><a href="deep-learning.html#cb733-12"></a>    model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb733-13"><a href="deep-learning.html#cb733-13"></a><span class="st">      </span><span class="kw">layer_embedding</span>(<span class="dt">input_dim =</span> max_features, <span class="dt">output_dim =</span> <span class="dv">32</span>) <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb733-14"><a href="deep-learning.html#cb733-14"></a><span class="st">      </span><span class="kw">layer_lstm</span>(<span class="dt">units =</span> <span class="dv">32</span>) <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb733-15"><a href="deep-learning.html#cb733-15"></a><span class="st">      </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">1</span>, <span class="dt">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)</span>
<span id="cb733-16"><a href="deep-learning.html#cb733-16"></a></span>
<span id="cb733-17"><a href="deep-learning.html#cb733-17"></a>    model <span class="op">|</span><span class="er">&gt;</span><span class="st"> </span><span class="kw">compile</span>(</span>
<span id="cb733-18"><a href="deep-learning.html#cb733-18"></a>      <span class="dt">optimizer =</span> <span class="st">&quot;rmsprop&quot;</span>,</span>
<span id="cb733-19"><a href="deep-learning.html#cb733-19"></a>      <span class="dt">loss =</span> <span class="st">&quot;binary_crossentropy&quot;</span>, </span>
<span id="cb733-20"><a href="deep-learning.html#cb733-20"></a>      <span class="dt">metrics =</span> <span class="st">&quot;acc&quot;</span></span>
<span id="cb733-21"><a href="deep-learning.html#cb733-21"></a>    )</span>
<span id="cb733-22"><a href="deep-learning.html#cb733-22"></a></span>
<span id="cb733-23"><a href="deep-learning.html#cb733-23"></a>    history &lt;-<span class="st"> </span><span class="kw">fit</span>(model, x_train, y_train, </span>
<span id="cb733-24"><a href="deep-learning.html#cb733-24"></a>      <span class="dt">epochs =</span> <span class="dv">10</span>, </span>
<span id="cb733-25"><a href="deep-learning.html#cb733-25"></a>      <span class="dt">batch_size =</span> <span class="dv">128</span>, </span>
<span id="cb733-26"><a href="deep-learning.html#cb733-26"></a>      <span class="dt">validation_data =</span> <span class="kw">list</span>(x_test, y_test),</span>
<span id="cb733-27"><a href="deep-learning.html#cb733-27"></a>      <span class="dt">verbose =</span> <span class="dv">1</span></span>
<span id="cb733-28"><a href="deep-learning.html#cb733-28"></a>    )</span>
<span id="cb733-29"><a href="deep-learning.html#cb733-29"></a></span>
<span id="cb733-30"><a href="deep-learning.html#cb733-30"></a>    predy &lt;-<span class="st"> </span><span class="kw">predict</span>(model, x_test) <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span></span>
<span id="cb733-31"><a href="deep-learning.html#cb733-31"></a>    accuracy &lt;-<span class="st"> </span><span class="kw">c</span>(accuracy, <span class="kw">mean</span>(<span class="kw">abs</span>(y_test <span class="op">==</span><span class="st"> </span><span class="kw">as.numeric</span>(predy))))</span>
<span id="cb733-32"><a href="deep-learning.html#cb733-32"></a>  }</span>
<span id="cb733-33"><a href="deep-learning.html#cb733-33"></a></span>
<span id="cb733-34"><a href="deep-learning.html#cb733-34"></a>  <span class="kw">tibble</span>(</span>
<span id="cb733-35"><a href="deep-learning.html#cb733-35"></a>    <span class="st">&quot;Max Features&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1000</span>, <span class="dv">3000</span>, <span class="dv">5000</span>, <span class="dv">10000</span>),</span>
<span id="cb733-36"><a href="deep-learning.html#cb733-36"></a>    <span class="st">&quot;Accuracy&quot;</span> =<span class="st"> </span>accuracy</span>
<span id="cb733-37"><a href="deep-learning.html#cb733-37"></a>  ) <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb733-38"><a href="deep-learning.html#cb733-38"></a><span class="st">    </span><span class="kw">kable</span>()</span>
<span id="cb733-39"><a href="deep-learning.html#cb733-39"></a></span>
<span id="cb733-40"><a href="deep-learning.html#cb733-40"></a>})</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">Max Features</th>
<th align="right">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1000</td>
<td align="right">0.83124</td>
</tr>
<tr class="even">
<td align="right">3000</td>
<td align="right">0.75764</td>
</tr>
<tr class="odd">
<td align="right">5000</td>
<td align="right">0.87820</td>
</tr>
<tr class="even">
<td align="right">10000</td>
<td align="right">0.86132</td>
</tr>
</tbody>
</table>
<p>Varying the dictionary size does not make a substantial impact on our estimates
of accuracy. However, the models do take a substantial amount of time to fit and
it is not clear we are finding the best fitting models in each case. For
example, the model using a dictionary size of 10,000 obtained an accuracy of
0.8721 in the text which is as different from the estimate obtained here as
are the differences between the models with different dictionary sizes.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="support-vector-machines.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="survival-analysis-and-censored-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": {}
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/danhalligan/ISLRv2-solutions/edit/master/10-deep-learning.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
